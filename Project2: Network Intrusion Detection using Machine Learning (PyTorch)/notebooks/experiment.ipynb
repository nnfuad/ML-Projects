# Network Intrusion Detection Project Notebook
# ==========================================
# This notebook explains each line of code for a PyTorch-based neural network for intrusion detection.

# -----------------------------
# 1. Import Libraries
# -----------------------------
import pandas as pd          # For data loading and manipulation
import torch                 # Core PyTorch library
import torch.nn as nn        # Neural network modules
from sklearn.preprocessing import LabelEncoder, StandardScaler  # Data preprocessing
from sklearn.model_selection import train_test_split            # Train-test split

# -----------------------------
# 2. Load Dataset
# -----------------------------
# Load train and test CSVs from the 'data/' folder
train_df = pd.read_csv('../data/kdd_train.csv')
test_df = pd.read_csv('../data/kdd_test.csv')

# Combine datasets for preprocessing
df = pd.concat([train_df, test_df])
print("Dataset Loaded")
print(df.head())

# Explanation:
# - We use pandas to load CSV files.
# - Concatenating ensures consistent preprocessing for train and test.

# -----------------------------
# 3. Encode Labels
# -----------------------------
# NSL-KDD labels are categorical strings. Convert them to 0 (normal) / 1 (attack)
label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['label'])

# Explanation:
# - LabelEncoder transforms string labels into integers.
# - 'normal' becomes 0, attacks become 1.

# -----------------------------
# 4. Prepare Features
# -----------------------------
X = df.drop('label', axis=1)  # All columns except the target
y = df['label']               # Target column

# Convert categorical features (like protocol_type) into numeric using one-hot encoding
X = pd.get_dummies(X)

# Explanation:
# - Neural networks require numeric inputs.
# - get_dummies converts categorical columns into multiple 0/1 columns.

# Split into training and test sets (20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Normalize features to mean=0, std=1
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Explanation:
# - StandardScaler ensures features have the same scale.
# - This speeds up neural network training and improves stability.

# -----------------------------
# 5. Convert to PyTorch Tensors
# -----------------------------
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1,1)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1,1)

# Explanation:
# - PyTorch models require tensors, not numpy arrays.
# - view(-1,1) reshapes labels into a column vector.

# -----------------------------
# 6. Define Neural Network
# -----------------------------
class IntrusionNet(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 64),  # First hidden layer, 64 neurons
            nn.ReLU(),                  # Activation function
            nn.Linear(64, 32),          # Second hidden layer, 32 neurons
            nn.ReLU(),
            nn.Linear(32, 1),           # Output layer, 1 neuron for binary classification
            nn.Sigmoid()                # Sigmoid to output probability
        )

    def forward(self, x):
        return self.model(x)

# Instantiate model
model = IntrusionNet(X_train_tensor.shape[1])

# Explanation:
# - Fully connected feedforward network.
# - ReLU adds non-linearity.
# - Sigmoid squashes output between 0 and 1.

# -----------------------------
# 7. Define Loss and Optimizer
# -----------------------------
criterion = nn.BCELoss()                # Binary cross-entropy loss
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer

# Explanation:
# - BCELoss measures difference between predicted probability and actual label.
# - Adam adapts learning rates during training for faster convergence.

# -----------------------------
# 8. Train the Model
# -----------------------------
epochs = 20
loss_values = []

for epoch in range(epochs):
    optimizer.zero_grad()            # Clear gradients from previous step
    outputs = model(X_train_tensor)  # Forward pass
    loss = criterion(outputs, y_train_tensor)  # Compute loss
    loss.backward()                  # Backpropagation
    optimizer.step()                 # Update weights

    loss_values.append(loss.item())

    if (epoch + 1) % 5 == 0:
        print(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}")

# Explanation:
# - optimizer.zero_grad(): prevent gradient accumulation
# - loss.backward(): computes gradients
# - optimizer.step(): updates model parameters

# -----------------------------
# 9. Evaluate the Model
# -----------------------------
with torch.no_grad():  # Disable gradient computation for evaluation
    y_pred = (model(X_test_tensor) > 0.5).float()  # Threshold at 0.5
    accuracy = (y_pred == y_test_tensor).float().mean()

print(f"Test Accuracy: {accuracy.item() * 100:.2f}%")

# Explanation:
# - torch.no_grad() avoids unnecessary gradient computation.
# - Compare predictions with labels to compute accuracy.

# -----------------------------
# 10. Visualize Training Loss
# -----------------------------
import matplotlib.pyplot as plt

plt.plot(loss_values)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Curve')
plt.show()

# Explanation:
# - Visualize how loss decreases over epochs
# - Useful to check for convergence or overfitting
